{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的一些应用需要**从语义方面深入理解文本**:\n",
    "- 问答系统\n",
    "- 语境识别\n",
    "- 语音识别\n",
    "\n",
    "文本语义学专门研究理解文本或语言的意义\n",
    "\n",
    "情感分析也许是文本分析中最主流的应用,有大量关注不同文本资源情感分析的手册,网站和应用,其内容涵盖从企业调查到电影评论.\n",
    "\n",
    "情感分析的关键是分析文本易理解其表达的观点,以及情绪和青苔等其他因素.\n",
    "\n",
    "通常相比于**在客观内容上**,情感分析能够在主观内容上更好的工作.\n",
    "\n",
    "在情感分析方面,我们将研究如何使**用有监督机器学习技术分析情感**,同时也是**用几个基于字典的无监督技术深入研究自然语言的情感,情绪和情态**.\n",
    "\n",
    "## 语义分析\n",
    "\n",
    "第三章介绍了自然语言不同的结构组成,包括词性标注(POS),组块分析(chunking)和语法.这些概念都属于文本数据的语法和结构分析.\n",
    "\n",
    "然而,研究单词,短语,从句之间的**语法关系**,纯粹是**基于它们的位置,句法和结构**.\n",
    "\n",
    "我们将在语义分析的基础上广泛讨论以下主题:\n",
    "- 探索WordNet和同义词集\n",
    "- 分析词汇语义关系\n",
    "- 语义消歧\n",
    "- 命名实体识别\n",
    "- 分析语义的表示方法\n",
    "\n",
    "## 探索WordNet\n",
    "wordnet该词汇数据库由名词,形容词,动词和副词组成,而且基于相同的概念将相关的单词分为一组,称之为认知同义词集或同义词集.\n",
    "\n",
    "### 理解同义词集\n",
    "同义词是将每个事物联系在一起的非常重要的概念和结构之一,所以我们从研究同义词集开始探索WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Synsets:', 5)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "term = 'fruit'\n",
    "synsets = wn.synsets(term)\n",
    "#display total synsets\n",
    "print('Total Synsets:', len(synsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Synset:', Synset('fruit.n.01'))\n",
      "('Part of speech:', u'noun.plant')\n",
      "('Definition:', u'the ripened reproductive body of a seed plant')\n",
      "('Lemmas:', [u'fruit'])\n",
      "('Examples:', [])\n",
      "\n",
      "('Synset:', Synset('yield.n.03'))\n",
      "('Part of speech:', u'noun.artifact')\n",
      "('Definition:', u'an amount of a product')\n",
      "('Lemmas:', [u'yield', u'fruit'])\n",
      "('Examples:', [])\n",
      "\n",
      "('Synset:', Synset('fruit.n.03'))\n",
      "('Part of speech:', u'noun.event')\n",
      "('Definition:', u'the consequence of some effort or action')\n",
      "('Lemmas:', [u'fruit'])\n",
      "('Examples:', [u'he lived long enough to see the fruit of his policies'])\n",
      "\n",
      "('Synset:', Synset('fruit.v.01'))\n",
      "('Part of speech:', u'verb.creation')\n",
      "('Definition:', u'cause to bear fruit')\n",
      "('Lemmas:', [u'fruit'])\n",
      "('Examples:', [])\n",
      "\n",
      "('Synset:', Synset('fruit.v.02'))\n",
      "('Part of speech:', u'verb.creation')\n",
      "('Definition:', u'bear fruit')\n",
      "('Lemmas:', [u'fruit'])\n",
      "('Examples:', [u'the trees fruited early this year'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets:\n",
    "    print('Synset:', synset)\n",
    "    print('Part of speech:', synset.lexname()) # 同义词的语音部分\n",
    "    print('Definition:', synset.definition())\n",
    "    print('Lemmas:', synset.lemma_names())\n",
    "    print('Examples:', synset.examples()) #造句\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析词汇的语义关系\n",
    "文本语义学指的是意思和内容的研究.\n",
    "\n",
    "- 蕴含\n",
    "    通常蕴含指的是同样事件或行为,这些事件或行为在逻辑上涉及或者其他已经发生或将要发生的行为或事件相关联.\n",
    "    理想情况下,这适用于表示某些特定行为的动词."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('walk.v.01') --entails--> [Synset('step.v.01')]\n",
      "Synset('eat.v.01') --entails--> [Synset('chew.v.01'), Synset('swallow.v.01')]\n",
      "Synset('digest.v.01') --entails--> [Synset('consume.v.02')]\n"
     ]
    }
   ],
   "source": [
    "#entailments蕴含\n",
    "for action in ['walk','eat','digest']:\n",
    "    action_syn = wn.synsets(action, pos='v')[0]\n",
    "    print action_syn, '--entails-->', action_syn.entailments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同音词和同形异义词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank.n.01 - sloping land (especially the slope beside a body of water)\n",
      "depository_financial_institution.n.01 - a financial institution that accepts deposits and channels the money into lending activities\n",
      "bank.n.03 - a long ridge or pile\n",
      "bank.n.04 - an arrangement of similar objects in a row or in tiers\n",
      "bank.n.05 - a supply or stock held in reserve for future use (especially in emergencies)\n",
      "bank.n.06 - the funds held by a gambling house or the dealer in some gambling games\n",
      "bank.n.07 - a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "savings_bank.n.02 - a container (usually with a slot in the top) for keeping money at home\n",
      "bank.n.09 - a building in which the business of banking transacted\n",
      "bank.n.10 - a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "bank.v.01 - tip laterally\n",
      "bank.v.02 - enclose with a bank\n",
      "bank.v.03 - do business with a bank or keep an account at a bank\n",
      "bank.v.04 - act as the banker in a game or in gambling\n",
      "bank.v.05 - be in the banking business\n",
      "deposit.v.02 - put into a bank account\n",
      "bank.v.07 - cover with ashes so to control the rate of burning\n",
      "trust.v.01 - have confidence or faith in\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('bank'):\n",
    "    print synset.name(),'-',synset.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同义词和反义词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym: large.a.01\n",
      "Definition: above average in size or number or quantity or magnitude or extent\n",
      "Antonym: small.a.01\n",
      "Definition: limited or below average in number or quantity or magnitude or extent\n"
     ]
    }
   ],
   "source": [
    "term = 'large'\n",
    "synsets = wn.synsets(term)\n",
    "adj_large = synsets[1]\n",
    "adj_large = adj_large.lemmas()[0]\n",
    "adj_large_synonym = adj_large.synset()\n",
    "adj_large_antonym = adj_large.antonyms()[0].synset()\n",
    "#print synonym and antonym\n",
    "print 'Synonym:', adj_large_synonym.name()\n",
    "print 'Definition:', adj_large_synonym.definition()\n",
    "print 'Antonym:', adj_large_antonym.name()\n",
    "print 'Definition:', adj_large_antonym.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Synonym:', u'rich_people.n.01')\n",
      "('Definition:', u'people who have possessions and wealth (considered as a group)')\n",
      "('Antonym:', u'poor_people.n.01')\n",
      "('Definition:', u'people without possessions or wealth (considered as a group)')\n",
      "--------------------\n",
      "('Synonym:', u'rich.a.01')\n",
      "('Definition:', u'possessing material wealth')\n",
      "('Antonym:', u'poor.a.02')\n",
      "('Definition:', u'having little money or few possessions')\n",
      "--------------------\n",
      "('Synonym:', u'rich.a.02')\n",
      "('Definition:', u'having an abundant supply of desirable qualities or substances (especially natural resources)')\n",
      "('Antonym:', u'poor.a.04')\n",
      "('Definition:', u'lacking in specific resources, qualities or substances')\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "term = 'rich'\n",
    "synsets = wn.synsets(term)[:3]\n",
    "\n",
    "#print synonym and antonym for different synsets\n",
    "for synset in synsets:\n",
    "    rich = synset.lemmas()[0]\n",
    "    rich_synonym = rich.synset()\n",
    "    rich_antonym = rich.antonyms()[0].synset()\n",
    "    print('Synonym:', rich_synonym.name())\n",
    "    print('Definition:', rich_synonym.definition())\n",
    "    print('Antonym:', rich_antonym.name())\n",
    "    print('Definition:', rich_antonym.definition())\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上位词和下位词\n",
    "同义词集表示具有独立语义和概念的词,基于相似性和内容而联系或关联在一起.\n",
    "\n",
    "它们以一种层次结构连接在一起,表示一种is-a关系.\n",
    "\n",
    "下位词和上位词帮助我们在层次结构中探索相关的概念.\n",
    "\n",
    "下位词所指的概念和实体是高层概念或实体的子类,与其超类相比,下位词具有更具体的意义和语境."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tree.n.01\n",
      "Definition: a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n"
     ]
    }
   ],
   "source": [
    "term = 'tree'\n",
    "synsets = wn.synsets(term)\n",
    "tree = synsets[0]\n",
    "\n",
    "#print the entity and its meaning\n",
    "print 'Name:', tree.name()\n",
    "print 'Definition:', tree.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Hyponyms:', 180)\n",
      "Sample Hyponyms\n",
      "--------------------\n",
      "(u'aalii.n.01', '-', u'a small Hawaiian tree with hard dark wood')\n",
      "(u'acacia.n.01', '-', u'any of various spiny trees or shrubs of the genus Acacia')\n",
      "(u'african_walnut.n.01', '-', u'tropical African timber tree with wood that resembles mahogany')\n",
      "(u'albizzia.n.01', '-', u'any of numerous trees of the genus Albizia')\n",
      "(u'alder.n.02', '-', u'north temperate shrubs or trees having toothed leaves and conelike fruit; bark is used in tanning and dyeing and the wood is rot-resistant')\n",
      "(u'angelim.n.01', '-', u'any of several tropical American trees of the genus Andira')\n",
      "(u'angiospermous_tree.n.01', '-', u'any tree having seeds and ovules contained in the ovary')\n",
      "(u'anise_tree.n.01', '-', u'any of several evergreen shrubs and small trees of the genus Illicium')\n",
      "(u'arbor.n.01', '-', u'tree (as opposed to shrub)')\n",
      "(u'aroeira_blanca.n.01', '-', u'small resinous tree or shrub of Brazil')\n"
     ]
    }
   ],
   "source": [
    "#print total hyponyms and some sample hyponyms for 'tree'\n",
    "#作为超类的下位词具有更一般的意义和语境\n",
    "hyponyms = tree.hyponyms()\n",
    "print('Total Hyponyms:', len(hyponyms))  #输出tree有多少个下位词,我们可以看到下位词是一类具体的树.\n",
    "print('Sample Hyponyms')\n",
    "print('-'*20)\n",
    "for hyponym in hyponyms[:10]:\n",
    "    print(hyponym.name(),'-',hyponym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('woody_plant.n.01')]\n"
     ]
    }
   ],
   "source": [
    "#显示tree的直接超类\n",
    "hypernyms = tree.hypernyms()\n",
    "print(hypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Hypernym paths:', 1)\n"
     ]
    }
   ],
   "source": [
    "#get total hierarchy pathways for 'tree'\n",
    "hypernym_paths = tree.hypernym_paths()\n",
    "print('Total Hypernym paths:', len(hypernym_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernym Hierarchy\n",
      "entity.n.01->physical_entity.n.01->object.n.01->whole.n.02->living_thing.n.01->organism.n.01->plant.n.02->vascular_plant.n.01->woody_plant.n.01->tree.n.01\n"
     ]
    }
   ],
   "source": [
    "#print the entire hypernym hierarchy\n",
    "print('Hypernym Hierarchy')\n",
    "print('->'.join(synset.name() for synset in hypernym_paths[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的代码输出,我们可以看到完整的上位词层次结构显示了每个层次对应的上位词或超类.当你继续向下导航,你将获得更加具体的概念/实体,如果反方向导航,你将获得更加一般的概念/实体."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 整体词和部分词\n",
    "\n",
    "    整体词是一些实体,包含我们感兴趣的特定实体.基本上,**整体词指的是单词或实体间的关系,表示一个整体或整体的具体部分**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Member Holonyms:', 1)\n",
      "Member Holonyms for [tree]:-\n",
      "forest.n.01 - the trees and other plants in a large densely wooded area\n"
     ]
    }
   ],
   "source": [
    "member_holonyms = tree.member_holonyms()\n",
    "print('Total Member Holonyms:', len(member_holonyms))\n",
    "print('Member Holonyms for [tree]:-')\n",
    "\n",
    "for holonym in member_holonyms:\n",
    "    print holonym.name(),'-',holonym.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从输出可以看到,'forest'是tree的整体词,其语义上是正确的,因为森林是由树组成的.\n",
    "\n",
    "部分词表示一个单词或实体作为其他单词组成或一部分的语义关系."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Part Meronyms:', 5)\n",
      "Part Meronyms for [tree]:-\n",
      "----------------------------------------\n",
      "(u'burl.n.02', '-', u'a large rounded outgrowth on the trunk or branch of a tree')\n",
      "(u'crown.n.07', '-', u'the upper branches and leaves of a tree or other plant')\n",
      "(u'limb.n.02', '-', u'any of the main branches arising from the trunk or a bough of a tree')\n",
      "(u'stump.n.01', '-', u'the base part of a tree that remains standing after the tree has been felled')\n",
      "(u'trunk.n.01', '-', u'the main stem of a tree; usually covered with bark; the bole is usually the part that is commercially useful for lumber')\n"
     ]
    }
   ],
   "source": [
    "#part based meronyms for tree\n",
    "part_meronyms = tree.part_meronyms()\n",
    "print('Total Part Meronyms:', len(part_meronyms))\n",
    "print('Part Meronyms for [tree]:-')\n",
    "print('-'*40)\n",
    "for meronym in part_meronyms:\n",
    "    print(meronym.name(),'-',meronym.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面输出显示了tree的不同部分词,包含树的不同组成,如树干,树桩."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Substance Meronyms:', 2)\n",
      "Substance Meronyms for [tree]:-\n",
      "----------------------------------------\n",
      "(u'heartwood.n.01', '-', u'the older inactive central wood of a tree or woody plant; usually darker and denser than the surrounding sapwood')\n",
      "(u'sapwood.n.01', '-', u'newly formed outer wood lying between the cambium and the heartwood of a tree or woody plant; usually light colored; active in water conduction')\n"
     ]
    }
   ],
   "source": [
    "#substance based meronyms for tree\n",
    "substance_meronyms = tree.substance_meronyms()\n",
    "print('Total Substance Meronyms:', len(substance_meronyms))\n",
    "print('Substance Meronyms for [tree]:-')\n",
    "print('-'*40)\n",
    "\n",
    "for meronym in substance_meronyms:\n",
    "    print(meronym.name(),'-',meronym.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面输出显示了tree的衍生物体,如树的心材和边材."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 语义关系与相似度\n",
    "\n",
    "    前面章节,我们已经研究了各种与词汇语义关系相关的概念.\n",
    "\n",
    "    现在研究基于语义关系连接相似实体的方法,以及它们的相似度度量.(不同于第六章的度量方法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'tree', '-', u'a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms')\n",
      "(u'lion', '-', u'large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male')\n",
      "(u'tiger', '-', u'large feline of forests in most of Asia having a tawny coat with black stripes; endangered')\n",
      "(u'cat', '-', u'feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats')\n",
      "(u'dog', '-', u'a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds')\n"
     ]
    }
   ],
   "source": [
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "#create entities and extract names and definitions\n",
    "entities = [tree, lion, tiger, cat, dog]\n",
    "entity_names = [entity.name().split('.')[0] for entity in entities]\n",
    "entity_definitions = [entity.definition() for entity in entities]\n",
    "\n",
    "#print entities and their definitions\n",
    "for entity, definition in zip(entity_names, entity_definitions):\n",
    "    print(entity, '-', definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来,我们将基于这些实体共同的上位词来联系它们.对于每一对实体,我们将尽力寻找关系层次结构树中最低级别的上位词.\n",
    "\n",
    "相关联的实体应该拥有非常具体的上位词,不相关的实体则拥有非常抽象或通用的上位词."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tree       lion      tiger        cat        dog\n",
      "tree       tree   organism   organism   organism   organism\n",
      "lion   organism       lion    big_cat     feline  carnivore\n",
      "tiger  organism    big_cat      tiger     feline  carnivore\n",
      "cat    organism     feline     feline        cat  carnivore\n",
      "dog    organism  carnivore  carnivore  carnivore        dog\n"
     ]
    }
   ],
   "source": [
    "common_hypernyms = []\n",
    "for entity in entities:\n",
    "    #get pairwise lowest common hypernyms\n",
    "    common_hypernyms.append([entity.lowest_common_hypernyms(compared_entity)[0].name().split('.')[0] \n",
    "                            for compared_entity in entities])\n",
    "    \n",
    "#build pairwise lower common hypernym matrix\n",
    "common_hypernym_frame = pd.DataFrame(common_hypernyms,\n",
    "                                    index=entity_names,\n",
    "                                    columns=entity_names)\n",
    "\n",
    "#print the matrix\n",
    "print common_hypernym_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用语义概念来度量实体之间的语义相似性.我们将使用路径相似性(path similarity),\n",
    "\n",
    "它基于连接两个词的上位词/下位词的最短路径返回一个数值,其范围是[0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       tree  lion  tiger   cat   dog\n",
      "tree   1.00  0.07   0.07  0.08  0.13\n",
      "lion   0.07  1.00   0.33  0.25  0.17\n",
      "tiger  0.07  0.33   1.00  0.25  0.17\n",
      "cat    0.08  0.25   0.25  1.00  0.20\n",
      "dog    0.13  0.17   0.17  0.20  1.00\n"
     ]
    }
   ],
   "source": [
    "similarities = []\n",
    "for entity in entities:\n",
    "    #getpairwise similarities\n",
    "    similarities.append([round(entity.path_similarity(compared_entity),2) for compared_entity in entities])\n",
    "    \n",
    "#build pairwise similarity matrix\n",
    "similarity_frame = pd.DataFrame(similarities, index=entity_names, columns=entity_names)\n",
    "\n",
    "#print the matrix\n",
    "print similarity_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词义消歧\n",
    "词义基于单词如何使用且依赖于单词的语义,由语境决定.\n",
    "\n",
    "基于单词使用情况,识别单词正确语义和意义称为语义消歧.\n",
    "\n",
    "语义消歧是自然语言处理中典型问题,如提高搜索引擎结果的相关性,一致性等.\n",
    "\n",
    "有多种解决方法,包括基于词汇和字典的方法,有监督机器学习和无监督机器学习的方法.\n",
    "\n",
    "这里使用Lesk算法,它的基本原理是使用字典或词汇的定义为我们消除文本的歧义把我们感兴趣单词周围的一段文字与这些定义中的文字进行比较.\n",
    "\n",
    "主要目的是返回上下文的句子和我们要消歧的单词同义词集定义之间的最大数量的重叠词或词项."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sentence:', 'The fruits on that plant have ripened')\n",
      "('Word synset:', Synset('fruit.n.01'))\n",
      "('Corresponding definition:', u'the ripened reproductive body of a seed plant')\n",
      "\n",
      "('Sentence:', 'He finally reaped the fruit of his hard work as he won the race')\n",
      "('Word synset:', Synset('fruit.n.03'))\n",
      "('Corresponding definition:', u'the consequence of some effort or action')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#sample text and word to disambiguate\n",
    "samples = [('The fruits on that plant have ripened','n'),\n",
    "          ('He finally reaped the fruit of his hard work as he won the race','n')]\n",
    "\n",
    "word = 'fruit'\n",
    "#perform word sense disambiguation\n",
    "for sentence,pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print('Sentence:', sentence)\n",
    "    print('Word synset:', word_syn)\n",
    "    print('Corresponding definition:', word_syn.definition())\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sentence:', 'Lead is a very soft, malleable metal')\n",
      "('Word synset:', Synset('lead.n.02'))\n",
      "('Corresponding definition:', u'a soft heavy toxic malleable metallic element; bluish white when freshly cut but tarnishes readily to dull grey')\n",
      "\n",
      "('Sentence:', 'John is the actor who plays the lead in that movie')\n",
      "('Word synset:', Synset('star.n.04'))\n",
      "('Corresponding definition:', u'an actor who plays a principal role')\n",
      "\n",
      "('Sentence:', 'This road leads to nowhere')\n",
      "('Word synset:', Synset('run.v.23'))\n",
      "('Corresponding definition:', u'cause something to pass or lead somewhere')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sample text and word to disambiguate\n",
    "#消歧义的时候,提取出词语所在的上下文,同时对词语进行词性标注,然后根据这两个信息来对词语进行消歧\n",
    "samples = [('Lead is a very soft, malleable metal', 'n'),\n",
    "          ('John is the actor who plays the lead in that movie','n'),\n",
    "          ('This road leads to nowhere','v')]\n",
    "word = 'lead'\n",
    "#perform word sense disambiguation\n",
    "for sentence, pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print('Sentence:', sentence)\n",
    "    print('Word synset:', word_syn)\n",
    "    print('Corresponding definition:', word_syn.definition())\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命名实体识别\n",
    "更详细信息请参考nltk和斯坦福NLP的网站."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample document\n",
    "text = \"\"\"\n",
    "Bayern Munich, or FC Bayern, is a German sports club based in Munich, \n",
    "Bavaria, Germany. It is best known for its professional football team, \n",
    "which plays in the Bundesliga, the top tier of the German football \n",
    "league system, and is the most successful club in German football \n",
    "history, having won a record 26 national titles and 18 national cups. \n",
    "FC Bayern was founded in 1900 by eleven football players led by Franz John. \n",
    "Although Bayern won its first national championship in 1932, the club \n",
    "was not selected for the Bundesliga at its inception in 1963. The club \n",
    "had its period of greatest success in the middle of the 1970s when, \n",
    "under the captaincy of Franz Beckenbauer, it won the European Cup three \n",
    "times in a row (1974-76). Overall, Bayern has reached ten UEFA Champions \n",
    "League finals, most recently winning their fifth title in 2013 as part \n",
    "of a continental treble. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from normalization import parse_document\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Entity Name   Entity Type\n",
      "0              Bayern        PERSON\n",
      "1          Franz John        PERSON\n",
      "2   Franz Beckenbauer        PERSON\n",
      "3              Munich  ORGANIZATION\n",
      "4            European  ORGANIZATION\n",
      "5          Bundesliga  ORGANIZATION\n",
      "6              German           GPE\n",
      "7             Bavaria           GPE\n",
      "8             Germany           GPE\n",
      "9           FC Bayern  ORGANIZATION\n",
      "10               UEFA  ORGANIZATION\n",
      "11             Munich           GPE\n",
      "12             Bayern           GPE\n",
      "13            Overall           GPE\n"
     ]
    }
   ],
   "source": [
    "#tokenize sentences\n",
    "sentences = parse_document(text)\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "#tag sentences and use nltk's Named Entity chunker\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences] #词性标注\n",
    "ne_chunked_sents = [nltk.ne_chunk(tagged) for tagged in tagged_sentences]  #命名实体识别\n",
    "\n",
    "#extract all named entities\n",
    "named_entities = []\n",
    "for ne_tagged_sentence in ne_chunked_sents:\n",
    "    for tagged_tree in ne_tagged_sentence:\n",
    "        #extract only chunks having NE labels\n",
    "        if hasattr(tagged_tree, 'label'):\n",
    "            entity_name = ' '.join(c[0] for c in tagged_tree.leaves()) #get NE name,比如Franz John有两个单词需要拼接成完整的命名实体\n",
    "            \n",
    "            entity_type = tagged_tree.label()  #get NE category\n",
    "            named_entities.append((entity_name, entity_type))\n",
    "#get unique named entities\n",
    "named_entities = list(set(named_entities))\n",
    "#store named entities in a data frame\n",
    "entity_name = pd.DataFrame(named_entities,\n",
    "                          columns=['Entity Name','Entity Type'])\n",
    "\n",
    "#display results\n",
    "print entity_name\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来,我们使用斯坦福的NLP标记器进行分析,然后跟上面的nltk结果进行比较.\n",
    "\n",
    "需要下载Stanford NER资源:http://nlp.stanford.edu/software/stanford-ner-2014-08-27.zip\n",
    "\n",
    "关于斯坦福NER的详细信息,请访问网站:http://nlp.stanford.edu/soft-ware/CRF-NER.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set java path in environment variables\n",
    "java_path='/usr/bin/java'\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load stanford NER\n",
    "sn = StanfordNERTagger('/home/parallels/stanford-nlp/stanford-ner-2014-08-27/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                      path_to_jar='/home/parallels/stanford-nlp/stanford-ner-2014-08-27/stanford-ner.jar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Entity Name   Entity Type\n",
      "0         Franz John        PERSON\n",
      "1  Franz Beckenbauer        PERSON\n",
      "2            Germany      LOCATION\n",
      "3             Bayern  ORGANIZATION\n",
      "4            Bavaria      LOCATION\n",
      "5             Munich      LOCATION\n",
      "6          FC Bayern  ORGANIZATION\n",
      "7               UEFA  ORGANIZATION\n",
      "8      Bayern Munich  ORGANIZATION\n"
     ]
    }
   ],
   "source": [
    "ne_annotated_sentences = [sn.tag(sent) for sent in tokenized_sentences]\n",
    "\n",
    "named_entities = []\n",
    "for sentence in ne_annotated_sentences:\n",
    "    temp_entity_name = ''\n",
    "    temp_named_entity = None\n",
    "    for term, tag in sentence:\n",
    "        if tag != 'O':\n",
    "            temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "            temp_named_entity = (temp_entity_name, tag)\n",
    "        else:\n",
    "            if temp_named_entity:\n",
    "                named_entities.append(temp_named_entity)\n",
    "                temp_entity_name = ''\n",
    "                temp_named_entity = None\n",
    "\n",
    "named_entities = list(set(named_entities))\n",
    "entity_frame = pd.DataFrame(named_entities, \n",
    "                            columns=['Entity Name', 'Entity Type'])\n",
    "print entity_frame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于命名实体识别器的好坏评估依赖于所分析的语料库类型.\n",
    "\n",
    "你可以使用与第三章相似的方法通过有监督的机器学习来训练预标记的语料库,从而建立自己的NER识别器.\n",
    "\n",
    "实际上,上述讨论的两个标记器已经使用预标记的语料库,如CoNLL,MUC和Penn Treebank进行了训练.\n",
    "\n",
    "## 分析语义表征\n",
    "到目前为止,我们一直在讨论不同单词单元间的语义和关系.\n",
    "\n",
    "如何表示一个或多个消息所传递的语义.\n",
    "\n",
    "命题逻辑和一阶逻辑的框架可以帮助我们进行语义表示.\n",
    "\n",
    "### 命题逻辑\n",
    "一个命题通常是一个声明,其值是二进制值真或假."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P:', 'He is hungry')\n",
      "('Q:', 'He will eat a sandwich')\n",
      "\n",
      "Expression Outcomes:-\n",
      "       P      Q  (P&Q)  (P|Q)  (P->Q)  (P<->Q)\n",
      "0  False  False  False  False    True     True\n",
      "1  False   True  False   True    True    False\n",
      "2   True  False  False   True   False    False\n",
      "3   True   True   True   True    True     True\n"
     ]
    }
   ],
   "source": [
    "#assign symbols and propositions\n",
    "symbol_P = 'P'\n",
    "symbol_Q = 'Q'\n",
    "proposition_P = 'He is hungry'\n",
    "proposition_Q = 'He will eat a sandwich'\n",
    "#assign various truth values to the propositions\n",
    "p_statuses = [False, False, True, True]\n",
    "q_statuses = [False, True, False, True]\n",
    "#assign the various expressions combining the logical operators\n",
    "conjunction = '(P&Q)'\n",
    "disjunction = '(P|Q)'\n",
    "implication = '(P->Q)'\n",
    "equivalence = '(P<->Q)'\n",
    "expressions = [conjunction, disjunction, implication, equivalence]\n",
    "\n",
    "#evaluate each expression using propositional logic\n",
    "results = []\n",
    "for status_p, status_q in zip(p_statuses, q_statuses):\n",
    "    dom = set([])\n",
    "    val = nltk.Valuation([(symbol_P, status_p), (symbol_Q, status_q)])\n",
    "    assignments = nltk.Assignment(dom)\n",
    "    model = nltk.Model(dom, val)\n",
    "    row = [status_p, status_q]\n",
    "    for expression in expressions:\n",
    "        #evaluate each expression based on proposition truth values\n",
    "        result = model.evaluate(expression, assignments)\n",
    "        row.append(result)\n",
    "    results.append(row)\n",
    "\n",
    "#build the result table\n",
    "columns = [symbol_P, symbol_Q, conjunction, disjunction, implication, equivalence]\n",
    "result_frame = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "#display results\n",
    "print('P:', proposition_P)\n",
    "print('Q:', proposition_Q)\n",
    "print\n",
    "print('Expression Outcomes:-')\n",
    "print(result_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一阶逻辑\n",
    "命名逻辑有几个局限,如没有能力表示事实或复杂的关系和推理.\n",
    "\n",
    "对于每个新的命题,我们需要同一个符号表示,这使得产生事实非常困难,因此命名逻辑表现能力十分有限.\n",
    "\n",
    "一阶逻辑(FOL)具有如函数,量词,关系,连接词和符号等特征.\n",
    "\n",
    "本节主要内容是了解如何在python中表示**FOL表达式**,以及如何使用**基于某些目标和预定义规则和事件的证据来执行后续推理**.\n",
    "\n",
    "有几个定理证明器(prover)可以用于评价表达式和证明定理.\n",
    "\n",
    "nltk程序包有三个主要的不同类型的定理证明器:Prover9, TableauProver和ResolutionProver.\n",
    "\n",
    "Prover9,免费使用,www.cs.unm.edu/~mccume/prover9/download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "#for reading FOL expressions\n",
    "read_expr = nltk.sem.Expression.fromstring\n",
    "#initialize theorem provers (you can choose any)\n",
    "os.environ['PROVER9'] = r'/home/parallels/LADR-2009-11A/bin'\n",
    "prover = nltk.Prover9()\n",
    "#i use the following one for our examples\n",
    "prove = nltk.ResolutionProver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Found prover9: /home/parallels/LADR-2009-11A/bin/prover9]\n",
      "Calling: /home/parallels/LADR-2009-11A/bin/prover9\n",
      "Args: []\n",
      "Input:\n",
      " assign(max_seconds, 60).\n",
      "\n",
      "clear(auto_denials).\n",
      "formulas(assumptions).\n",
      "    jumps_over(fox,dog).\n",
      "    all x all y jumps_over(x,y).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "    jumps_over(dog,fox).\n",
      "end_of_list.\n",
      "\n",
      " \n",
      "\n",
      "Return code: 0\n",
      "stdout:\n",
      " ============================== Prover9 ===============================\n",
      "Prover9 (64) version 2009-11A, November 2009.\n",
      "Process 16769 was started by parallels on ubuntu,\n",
      "Mon Jul 16 23:38:48 2018\n",
      "The command was \"/home/parallels/LADR-2009-11A/bin/prover9\".\n",
      "============================== end of head ===========================\n",
      "\n",
      "============================== INPUT =================================\n",
      "assign(max_seconds,60).\n",
      "clear(auto_denials).\n",
      "\n",
      "formulas(assumptions).\n",
      "jumps_over(fox,dog).\n",
      "(all x all y jumps_over(x,y)).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "jumps_over(dog,fox).\n",
      "end_of_list.\n",
      "\n",
      "============================== end of input ==========================\n",
      "\n",
      "============================== PROCESS NON-CLAUSAL FORMULAS ==========\n",
      "\n",
      "% Formulas that are not ordinary clauses:\n",
      "1 (all x all y jumps_over(x,y)) # label(non_clause).  [assumption].\n",
      "2 jumps_over(dog,fox) # label(non_clause) # label(goal).  [goal].\n",
      "\n",
      "============================== end of process non-clausal formulas ===\n",
      "\n",
      "============================== PROCESS INITIAL CLAUSES ===============\n",
      "\n",
      "% Clauses before input processing:\n",
      "\n",
      "formulas(usable).\n",
      "end_of_list.\n",
      "\n",
      "formulas(sos).\n",
      "jumps_over(fox,dog).  [assumption].\n",
      "jumps_over(x,y).  [clausify(1)].\n",
      "-jumps_over(dog,fox).  [deny(2)].\n",
      "end_of_list.\n",
      "\n",
      "formulas(demodulators).\n",
      "end_of_list.\n",
      "\n",
      "============================== PREDICATE ELIMINATION =================\n",
      "\n",
      "Eliminating jumps_over/2\n",
      "3 -jumps_over(dog,fox).  [deny(2)].\n",
      "4 jumps_over(fox,dog).  [assumption].\n",
      "5 jumps_over(x,y).  [clausify(1)].\n",
      "Derived: $F.  [resolve(3,a,5,a)].\n",
      "\n",
      "============================== end predicate elimination =============\n",
      "\n",
      "Term ordering decisions:\n",
      "Predicate symbol precedence:  predicate_order([ ]).\n",
      "Function symbol precedence:  function_order([ ]).\n",
      "After inverse_order:  (no changes).\n",
      "Unfolding symbols: (none).\n",
      "\n",
      "Auto_inference settings:\n",
      "  % set(neg_binary_resolution).  % (HNE depth_diff=0)\n",
      "  % clear(ordered_res).  % (HNE depth_diff=0)\n",
      "  % set(ur_resolution).  % (HNE depth_diff=0)\n",
      "    % set(ur_resolution) -> set(pos_ur_resolution).\n",
      "    % set(ur_resolution) -> set(neg_ur_resolution).\n",
      "\n",
      "Auto_process settings:  (no changes).\n",
      "\n",
      "\u0007-------- Proof 1 -------- \n",
      "\n",
      "============================== PROOF =================================\n",
      "\n",
      "% Proof 1 at 0.00 (+ 0.01) seconds.\n",
      "% Length of proof is 5.\n",
      "% Level of proof is 2.\n",
      "% Maximum clause weight is 0.000.\n",
      "% Given clauses 0.\n",
      "\n",
      "1 (all x all y jumps_over(x,y)) # label(non_clause).  [assumption].\n",
      "2 jumps_over(dog,fox) # label(non_clause) # label(goal).  [goal].\n",
      "3 -jumps_over(dog,fox).  [deny(2)].\n",
      "5 jumps_over(x,y).  [clausify(1)].\n",
      "6 $F.  [resolve(3,a,5,a)].\n",
      "\n",
      "============================== end of proof ==========================\n",
      "\n",
      "============================== STATISTICS ============================\n",
      "\n",
      "Given=0. Generated=1. Kept=0. proofs=1.\n",
      "Usable=0. Sos=0. Demods=0. Limbo=0, Disabled=4. Hints=0.\n",
      "Kept_by_rule=0, Deleted_by_rule=0.\n",
      "Forward_subsumed=0. Back_subsumed=0.\n",
      "Sos_limit_deleted=0. Sos_displaced=0. Sos_removed=0.\n",
      "New_demodulators=0 (0 lex), Back_demodulated=0. Back_unit_deleted=0.\n",
      "Demod_attempts=0. Demod_rewrites=0.\n",
      "Res_instance_prunes=0. Para_instance_prunes=0. Basic_paramod_prunes=0.\n",
      "Nonunit_fsub_feature_tests=0. Nonunit_bsub_feature_tests=0.\n",
      "Megabytes=0.02.\n",
      "User_CPU=0.00, System_CPU=0.01, Wall_clock=0.\n",
      "\n",
      "============================== end of statistics =====================\n",
      "\n",
      "============================== end of search =========================\n",
      "\n",
      "THEOREM PROVED\n",
      "\n",
      "THEOREM PROVED\n",
      "\n",
      "Exiting with 1 proof.\n",
      "\n",
      "------ process 16769 exit (max_proofs) ------\n",
      "\u0007\n",
      "Process 16769 exit (max_proofs) Mon Jul 16 23:38:48 2018\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the rule expression\n",
    "rule = read_expr('all x. all y. (jumps_over(x,y))')\n",
    "\n",
    "#set the event occured\n",
    "event = read_expr('jumps_over(fox, dog)')\n",
    "\n",
    "#set the outcome we want to evaluate -- the goal\n",
    "test_outcome = read_expr('jumps_over(dog, fox)')\n",
    "\n",
    "#get the result\n",
    "prover.prove(goal=test_outcome, assumptions=[event, rule],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: /home/parallels/LADR-2009-11A/bin/prover9\n",
      "Args: []\n",
      "Input:\n",
      " assign(max_seconds, 60).\n",
      "\n",
      "clear(auto_denials).\n",
      "formulas(assumptions).\n",
      "    -(studies(John,exam)).\n",
      "    all x (studies(x,exam) -> pass(x,exam)).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "    pass(John,exam).\n",
      "end_of_list.\n",
      "\n",
      " \n",
      "\n",
      "Return code: 2\n",
      "stdout:\n",
      " ============================== Prover9 ===============================\n",
      "Prover9 (64) version 2009-11A, November 2009.\n",
      "Process 16773 was started by parallels on ubuntu,\n",
      "Mon Jul 16 23:38:49 2018\n",
      "The command was \"/home/parallels/LADR-2009-11A/bin/prover9\".\n",
      "============================== end of head ===========================\n",
      "\n",
      "============================== INPUT =================================\n",
      "assign(max_seconds,60).\n",
      "clear(auto_denials).\n",
      "\n",
      "formulas(assumptions).\n",
      "-studies(John,exam).\n",
      "(all x (studies(x,exam) -> pass(x,exam))).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "pass(John,exam).\n",
      "end_of_list.\n",
      "\n",
      "============================== end of input ==========================\n",
      "\n",
      "============================== PROCESS NON-CLAUSAL FORMULAS ==========\n",
      "\n",
      "% Formulas that are not ordinary clauses:\n",
      "1 (all x (studies(x,exam) -> pass(x,exam))) # label(non_clause).  [assumption].\n",
      "2 pass(John,exam) # label(non_clause) # label(goal).  [goal].\n",
      "\n",
      "============================== end of process non-clausal formulas ===\n",
      "\n",
      "============================== PROCESS INITIAL CLAUSES ===============\n",
      "\n",
      "% Clauses before input processing:\n",
      "\n",
      "formulas(usable).\n",
      "end_of_list.\n",
      "\n",
      "formulas(sos).\n",
      "-studies(John,exam).  [assumption].\n",
      "-studies(x,exam) | pass(x,exam).  [clausify(1)].\n",
      "-pass(John,exam).  [deny(2)].\n",
      "end_of_list.\n",
      "\n",
      "formulas(demodulators).\n",
      "end_of_list.\n",
      "\n",
      "============================== PREDICATE ELIMINATION =================\n",
      "\n",
      "Eliminating studies/2\n",
      "\n",
      "Eliminating pass/2\n",
      "\n",
      "============================== end predicate elimination =============\n",
      "\n",
      "Term ordering decisions:\n",
      "Predicate symbol precedence:  predicate_order([ ]).\n",
      "Function symbol precedence:  function_order([ ]).\n",
      "After inverse_order:  (no changes).\n",
      "Unfolding symbols: (none).\n",
      "\n",
      "Auto_inference settings:\n",
      "  % set(neg_binary_resolution).  % (HNE depth_diff=0)\n",
      "  % clear(ordered_res).  % (HNE depth_diff=0)\n",
      "  % set(ur_resolution).  % (HNE depth_diff=0)\n",
      "    % set(ur_resolution) -> set(pos_ur_resolution).\n",
      "    % set(ur_resolution) -> set(neg_ur_resolution).\n",
      "\n",
      "Auto_process settings:  (no changes).\n",
      "\n",
      "\n",
      "============================== end of process initial clauses ========\n",
      "\n",
      "============================== CLAUSES FOR SEARCH ====================\n",
      "\n",
      "% Clauses after input processing:\n",
      "\n",
      "formulas(usable).\n",
      "end_of_list.\n",
      "\n",
      "formulas(sos).\n",
      "end_of_list.\n",
      "\n",
      "formulas(demodulators).\n",
      "end_of_list.\n",
      "\n",
      "============================== end of clauses for search =============\n",
      "\n",
      "============================== SEARCH ================================\n",
      "\n",
      "% Starting search at 0.01 seconds.\n",
      "\n",
      "============================== STATISTICS ============================\n",
      "\n",
      "Given=0. Generated=0. Kept=0. proofs=0.\n",
      "Usable=0. Sos=0. Demods=0. Limbo=0, Disabled=3. Hints=0.\n",
      "Kept_by_rule=0, Deleted_by_rule=0.\n",
      "Forward_subsumed=0. Back_subsumed=0.\n",
      "Sos_limit_deleted=0. Sos_displaced=0. Sos_removed=0.\n",
      "New_demodulators=0 (0 lex), Back_demodulated=0. Back_unit_deleted=0.\n",
      "Demod_attempts=0. Demod_rewrites=0.\n",
      "Res_instance_prunes=0. Para_instance_prunes=0. Basic_paramod_prunes=0.\n",
      "Nonunit_fsub_feature_tests=0. Nonunit_bsub_feature_tests=0.\n",
      "Megabytes=0.02.\n",
      "User_CPU=0.01, System_CPU=0.02, Wall_clock=0.\n",
      "\n",
      "============================== end of statistics =====================\n",
      "\n",
      "============================== end of search =========================\n",
      "\n",
      "SEARCH FAILED\n",
      "\n",
      "SEARCH FAILED\n",
      "\n",
      "Exiting with failure.\n",
      "\n",
      "------ process 16773 exit (sos_empty) ------\n",
      "\u0007\n",
      "Process 16773 exit (sos_empty) Mon Jul 16 23:38:49 2018\n",
      " \n",
      "\n",
      "Calling: /home/parallels/LADR-2009-11A/bin/prover9\n",
      "Args: []\n",
      "Input:\n",
      " assign(max_seconds, 60).\n",
      "\n",
      "clear(auto_denials).\n",
      "formulas(assumptions).\n",
      "    studies(Pierre,exam).\n",
      "    all x (studies(x,exam) -> pass(x,exam)).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "    pass(Pierre,exam).\n",
      "end_of_list.\n",
      "\n",
      " \n",
      "\n",
      "Return code: 0\n",
      "stdout:\n",
      " ============================== Prover9 ===============================\n",
      "Prover9 (64) version 2009-11A, November 2009.\n",
      "Process 16774 was started by parallels on ubuntu,\n",
      "Mon Jul 16 23:38:50 2018\n",
      "The command was \"/home/parallels/LADR-2009-11A/bin/prover9\".\n",
      "============================== end of head ===========================\n",
      "\n",
      "============================== INPUT =================================\n",
      "assign(max_seconds,60).\n",
      "clear(auto_denials).\n",
      "\n",
      "formulas(assumptions).\n",
      "studies(Pierre,exam).\n",
      "(all x (studies(x,exam) -> pass(x,exam))).\n",
      "end_of_list.\n",
      "\n",
      "formulas(goals).\n",
      "pass(Pierre,exam).\n",
      "end_of_list.\n",
      "\n",
      "============================== end of input ==========================\n",
      "\n",
      "============================== PROCESS NON-CLAUSAL FORMULAS ==========\n",
      "\n",
      "% Formulas that are not ordinary clauses:\n",
      "1 (all x (studies(x,exam) -> pass(x,exam))) # label(non_clause).  [assumption].\n",
      "2 pass(Pierre,exam) # label(non_clause) # label(goal).  [goal].\n",
      "\n",
      "============================== end of process non-clausal formulas ===\n",
      "\n",
      "============================== PROCESS INITIAL CLAUSES ===============\n",
      "\n",
      "% Clauses before input processing:\n",
      "\n",
      "formulas(usable).\n",
      "end_of_list.\n",
      "\n",
      "formulas(sos).\n",
      "studies(Pierre,exam).  [assumption].\n",
      "-studies(x,exam) | pass(x,exam).  [clausify(1)].\n",
      "-pass(Pierre,exam).  [deny(2)].\n",
      "end_of_list.\n",
      "\n",
      "formulas(demodulators).\n",
      "end_of_list.\n",
      "\n",
      "============================== PREDICATE ELIMINATION =================\n",
      "\n",
      "Eliminating studies/2\n",
      "3 -studies(x,exam) | pass(x,exam).  [clausify(1)].\n",
      "4 studies(Pierre,exam).  [assumption].\n",
      "Derived: pass(Pierre,exam).  [resolve(3,a,4,a)].\n",
      "\n",
      "Eliminating pass/2\n",
      "5 pass(Pierre,exam).  [resolve(3,a,4,a)].\n",
      "6 -pass(Pierre,exam).  [deny(2)].\n",
      "Derived: $F.  [resolve(5,a,6,a)].\n",
      "\n",
      "============================== end predicate elimination =============\n",
      "\n",
      "Term ordering decisions:\n",
      "Predicate symbol precedence:  predicate_order([ ]).\n",
      "Function symbol precedence:  function_order([ ]).\n",
      "After inverse_order:  (no changes).\n",
      "Unfolding symbols: (none).\n",
      "\n",
      "Auto_inference settings:\n",
      "  % set(neg_binary_resolution).  % (HNE depth_diff=0)\n",
      "  % clear(ordered_res).  % (HNE depth_diff=0)\n",
      "  % set(ur_resolution).  % (HNE depth_diff=0)\n",
      "    % set(ur_resolution) -> set(pos_ur_resolution).\n",
      "    % set(ur_resolution) -> set(neg_ur_resolution).\n",
      "\n",
      "Auto_process settings:  (no changes).\n",
      "\n",
      "\u0007-------- Proof 1 -------- \n",
      "\n",
      "============================== PROOF =================================\n",
      "\n",
      "% Proof 1 at 0.01 (+ 0.01) seconds.\n",
      "% Length of proof is 7.\n",
      "% Level of proof is 3.\n",
      "% Maximum clause weight is 0.000.\n",
      "% Given clauses 0.\n",
      "\n",
      "1 (all x (studies(x,exam) -> pass(x,exam))) # label(non_clause).  [assumption].\n",
      "2 pass(Pierre,exam) # label(non_clause) # label(goal).  [goal].\n",
      "3 -studies(x,exam) | pass(x,exam).  [clausify(1)].\n",
      "4 studies(Pierre,exam).  [assumption].\n",
      "5 pass(Pierre,exam).  [resolve(3,a,4,a)].\n",
      "6 -pass(Pierre,exam).  [deny(2)].\n",
      "7 $F.  [resolve(5,a,6,a)].\n",
      "\n",
      "============================== end of proof ==========================\n",
      "\n",
      "============================== STATISTICS ============================\n",
      "\n",
      "Given=0. Generated=1. Kept=0. proofs=1.\n",
      "Usable=0. Sos=0. Demods=0. Limbo=0, Disabled=5. Hints=0.\n",
      "Kept_by_rule=0, Deleted_by_rule=0.\n",
      "Forward_subsumed=0. Back_subsumed=0.\n",
      "Sos_limit_deleted=0. Sos_displaced=0. Sos_removed=0.\n",
      "New_demodulators=0 (0 lex), Back_demodulated=0. Back_unit_deleted=0.\n",
      "Demod_attempts=0. Demod_rewrites=0.\n",
      "Res_instance_prunes=0. Para_instance_prunes=0. Basic_paramod_prunes=0.\n",
      "Nonunit_fsub_feature_tests=0. Nonunit_bsub_feature_tests=0.\n",
      "Megabytes=0.02.\n",
      "User_CPU=0.01, System_CPU=0.01, Wall_clock=0.\n",
      "\n",
      "============================== end of statistics =====================\n",
      "\n",
      "============================== end of search =========================\n",
      "\n",
      "THEOREM PROVED\n",
      "\n",
      "THEOREM PROVED\n",
      "\n",
      "Exiting with 1 proof.\n",
      "\n",
      "------ process 16774 exit (max_proofs) ------\n",
      "\u0007\n",
      "Process 16774 exit (max_proofs) Mon Jul 16 23:38:50 2018\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the rule expression\n",
    "rule = read_expr('all x. (studies(x, exam) -> pass(x, exam))')\n",
    "\n",
    "#set the events and outcome we want to determine\n",
    "event1 = read_expr('-studies(John, exam)')\n",
    "test_outcome1 = read_expr('pass(John, exam)')\n",
    "\n",
    "event2 = read_expr('studies(Pierre, exam)')\n",
    "test_outcome2 = read_expr('pass(Pierre, exam)')\n",
    "\n",
    "#get results\n",
    "prover.prove(goal=test_outcome1,\n",
    "            assumptions=[event1, rule],\n",
    "            verbose=True)\n",
    "\n",
    "prover.prove(goal=test_outcome2,\n",
    "            assumptions=[event2, rule],\n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define symbols (entities\\functions) and their values\n",
    "rules = \"\"\"\n",
    "rover=>r\n",
    "felix=>r\n",
    "garfield=>g\n",
    "alex=>a\n",
    "dog=>{r, a}\n",
    "cat=>{g}\n",
    "fox=>{f}\n",
    "runs=>{a, f}\n",
    "sleeps=>{r, g}\n",
    "jumps_over => {(f,g), (a,g), (f,r), (a,r)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rover': 'r', 'runs': set([('f',), ('a',)]), 'alex': 'a', 'sleeps': set([('r',), ('g',)]), 'felix': 'r', 'fox': set([('f',)]), 'dog': set([('a',), ('r',)]), 'jumps_over': set([('a', 'g'), ('f', 'g'), ('a', 'r'), ('f', 'r')]), 'cat': set([('g',)]), 'garfield': 'g'}\n"
     ]
    }
   ],
   "source": [
    "val = nltk.Valuation.fromstring(rules)\n",
    "#view the valuation object of symbols and their assigned values (dictionary)\n",
    "\n",
    "print val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#define domain and build FOL based model\n",
    "dom = {'r','f','g','a'}\n",
    "\n",
    "m = nltk.Model(dom, val)\n",
    "\n",
    "#evaluate various expressions\n",
    "print m.evaluate('jumps_over(felix, rover) & dog(rover) & runs(rover)', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print m.evaluate('jumps_over(felix, rover) & dog(rover) & -runs(rover)', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print m.evaluate('jumps_over(alex, garfield) & dog(alex) & cat(garfield) & sleeps(garfield)', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assign rover to x and felix to y in the domain\n",
    "g = nltk.Assignment(dom, [('x','r'),('y','f')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#evaluate more expressions based on above assigned symbols\n",
    "print m.evaluate('runs(y) & jumps_over(y, x) & sleeps(x)', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print m.evaluate('exists y. (fox(y) & runs(y))', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['a', 'f'])\n"
     ]
    }
   ],
   "source": [
    "#who are the animals who run\n",
    "formula = read_expr('runs(x)')\n",
    "print m.satisfiers(formula, 'x', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['f'])\n"
     ]
    }
   ],
   "source": [
    "#animals who run and are also a fox?\n",
    "formula = read_expr('runs(x) & fox(x)')\n",
    "print m.satisfiers(formula, 'x', g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感分析\n",
    "非结构化的文本数据,也主要可以分为两大类:基于事实类(客观)和基于观念类(主观)\n",
    "\n",
    "情感分析定义为使用如NLP,字典资源,语言学和机器学习等技术进行主观意见相关的信息提取,\n",
    "\n",
    "并尝试用这些来计算文本文档所表示的极性的过程.\n",
    "\n",
    "所谓极性,是指文件是否表示积极,消极或中性的情绪.\n",
    "\n",
    "可以在几个层次上进行情感分析,分别是单个语句层次,段落层次和整篇文档作为一个整体.情感分析一般基于整篇文档计算,或是逐句计算之后累加在一起.\n",
    "\n",
    "语义的极性分析通常为文档所表达的正面和负面情感赋予一些分值,然后基于累计的分值为文档赋予一个标签.\n",
    "\n",
    "这里介绍两种情感分析的两种主要技术:\n",
    "- 有监督的机器学习\n",
    "- 无监督的机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## IMDb电影评论的情感分析\n",
    "电影评论数据集可以从http://ai.stanford.edu/~amaas/data/sentiment/ 上下载\n",
    "\n",
    "### 安装依赖程序包\n",
    "\n",
    "- 数据获取和格式化\n",
    "    \n",
    "    下载数据之后,使用review_data_extractor.py文件以及本章的代码文件从解压缩目录中提取每个评论,解析它们,整齐地将它们格式化到数据框.\n",
    "- 文本规范化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from HTMLParser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "        \n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "        \n",
    "    def get_data(self):\n",
    "        return ' '.join(self.fed)\n",
    "    \n",
    "def strip_html(text):\n",
    "    html_stripper = MLStripper()\n",
    "    html_stripper.feed(text)\n",
    "    return html_stripper.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_accented_characters(text):\n",
    "    '''对特殊的重音字符规范化'''\n",
    "    text = unicodedata.normalize('NFKD',text.decode('utf8')).encode('ascii', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, lemmatize=True, only_text_chars=False, tokenize=False):\n",
    "    normalized_corpus = []\n",
    "    \n",
    "    for index, text in enumerate(corpus):\n",
    "        text = normalize_accented_characters(text)\n",
    "        text = html_parser.unescape(text)\n",
    "        text = strip_html(text)\n",
    "        text = expand_contractions(text, CONTRACTION_MAP)\n",
    "        if lemmatize:\n",
    "            text = lemmatize_text(text)\n",
    "        else:\n",
    "            text = text.lower()\n",
    "            \n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_stopwords(text)\n",
    "    if only_text_chars:\n",
    "        text = keep_text_characters(text)\n",
    "        \n",
    "    if tokenize:\n",
    "        text = tokenize_text(text)\n",
    "        normalized_corpus.append(text)\n",
    "    else:\n",
    "        normalized_corpus.append(text)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def build_feature_matrix(documents, feature_type='frequency', ngram_range=(1,1), min_df=0.0, max_df=1.0):\n",
    "    feature_type = feature_type.lower().strip()\n",
    "    \n",
    "    if feature_type == 'binary':\n",
    "        vectorizer = CounterVectorizer(binary=True, min_df=min_df,\n",
    "                                      max_df=max_df, ngram_range=ngram_range)\n",
    "    elif feature_type == 'frequency':\n",
    "        vectorizer = CounterVectorizer(binary=False, min_df=min_df,\n",
    "                                      max_df=max_df, ngram_range=ngram_range)\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
    "    else:\n",
    "        raise Exception('Wrong feature type entered. Possible values: \"binary\",\"frequency\",\"tfidf\"')\n",
    "        \n",
    "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
    "    return vectorizer, feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型性能评估(准确率,精确率,召回率和F1 score)\n",
    "    \n",
    "    查看混淆矩阵和每一类详细的分类报告."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_evaluation_metrics(true_labels, predicted_labels, positive_class=1):\n",
    "    print(\"Accuracy:\", np.round(metrics.accuracy_score(true_labels, predicted_labels),2))\n",
    "    \n",
    "    print('Precision:',np.round(metrics.precision_score(true_labels,predicted_labels,\n",
    "                                                       pos_label=positive_class,\n",
    "                                                       average='binary'),2))\n",
    "    print(\"Recall:\",np.round(metrics.recall_score(true_labels,predicted_labels,\n",
    "                                                 pos_label=positive_class,\n",
    "                                                 average='binary'),2))\n",
    "    print(\"F1 Score:\", np.round(metrics.f1_score(true_labels,predicted_labels,\n",
    "                                                pos_label=positive_class,\n",
    "                                                average='binary'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
    "    '''建立混淆矩阵'''\n",
    "    cm = metrics.confusion_matrix(y_true=true_labels,\n",
    "                                 y_pred=predicted_labels,\n",
    "                                 labels=classes)\n",
    "    cm_frame = pd.DataFrame(data=cm,columns=pd.MultiIndex(levels=[['Predicted:'],classes], labels=[[0,0],[0,1]]),\n",
    "                           index=pd.MultiIndex(levels=[['Actual:'],classes],labels=[[0,0],[0,1]]))\n",
    "    print(cm_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_classification_report(true_labels, predicted_labels,classes=[1,0]):\n",
    "    report = metrics.classification_report(y_true=true_labels,\n",
    "                                          y_pred=predicted_labels,\n",
    "                                          labels=classes)\n",
    "    print report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "#load movie reviews data\n",
    "dataset = pd.read_csv(r'movie_reviews.csv')\n",
    "#print sample data\n",
    "print dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare training and testing datasets\n",
    "train_data = dataset[:3500]\n",
    "test_data = dataset[3500:]\n",
    "\n",
    "train_reviews = np.array(train_data['review'])\n",
    "train_sentiments = np.array(train_data['sentiment'])\n",
    "test_reviews = np.array(test_data['review'])\n",
    "test_sentiments = np.array(test_data['sentiment'])\n",
    "\n",
    "#prepare sample dataset for experiments\n",
    "sample_docs = [100,5817,7626,7356, 1008, 7155, 3533, 13010]\n",
    "sample_data = [(test_reviews[index], test_sentiments[index]) for index in sample_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有监督的机器学习技术\n",
    "1. 模型训练\n",
    "    - 训练数据规范化处理\n",
    "    - 特征提取以及建立特征集和特征向量\n",
    "    - 使用有监督的机器学习算法(SVM)建立预测模型\n",
    "\n",
    "2. 模型测试\n",
    "    - 测试数据规范化处理\n",
    "    - 使用训练特征向量生成器提取特征\n",
    "    - 实现训练好的模型预测测试评论的情感\n",
    "    - 评估模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from normalization import normalize_corpus\n",
    "from utils import build_feature_matrix\n",
    "\n",
    "#normalization\n",
    "norm_train_reviews = normalize_corpus(train_reviews, lemmatize=True, only_text_chars=True)\n",
    "\n",
    "#feature extraction\n",
    "vectorizer, train_features = build_feature_matrix(documents=norm_train_reviews, \n",
    "                                                 feature_type='tfidf',\n",
    "                                                 ngram_range=(1,1),\n",
    "                                                 min_df=0.0, max_df=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parallels/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=50,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用SVM算法构建模型\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#build the model\n",
    "svm = SGDClassifier(loss='hinge',n_iter=50)\n",
    "svm.fit(train_features, train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从测试数据集中提取特征\n",
    "\n",
    "#normalize reviews\n",
    "norm_test_reviews = normalize_corpus(test_reviews, lemmatize=True, only_text_chars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract features\n",
    "\n",
    "text_features = vectorizer.transform(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict sentiment for sample docs from test data\n",
    "for doc_index in sample_docs:\n",
    "    print 'Review:-'\n",
    "    print test_reviews[doc_index]\n",
    "    print 'Actual Labeled Sentiment:', test_sentiments[doc_index]\n",
    "    doc_features = test_features[doc_index]\n",
    "    predicted_sentiment = svm.predict(doc_features)[0]\n",
    "    print 'Predicted Sentiment:', predicted_sentiment\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来,我们对所有的测试集进行预测,并评估以下模型的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict the sentiment for test dataset movie reviews\n",
    "predicted_sentiments = svm.predict(test_features)\n",
    "\n",
    "#evaluate model prediciton performance\n",
    "from_utils import display_evaluation_metrics, display_confusion_matrix, display_classification_report\n",
    "\n",
    "#show performance metrics\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                          predicted_labels=predicted_sentiments,\n",
    "                          positive_class='positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show confusion matrix\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                        predicted_labels=predicted_sentiments,\n",
    "                        classes=['positive','negative'])\n",
    "\n",
    "#show detailed per-class classification report\n",
    "display_classification_report(true_labels=test_sentiments, predicted_labels=predicted_sentiments,\n",
    "                             classes=['positive','negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 无监督的词典技术\n",
    "用于情感分析的各种流行的词典如下所示:\n",
    "- AFINN词典\n",
    "    \n",
    "    极性基本上意味着正面的,负面的或中性的程度如何,及其对应的数值.\n",
    "    \n",
    "    下载地址:www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010\n",
    "    \n",
    "    也可以直接使用python版本的API直接使用该字典进行情感分析:github.com/fnielsen/afinn\n",
    "- Bing Liu 词典\n",
    "    \n",
    "    更多信息请参阅:https://www.cs.uic.edu/~liub/FBS/entiment-analysis.html#lexicon\n",
    "    \n",
    "    该词典的核心思想是当识别出文档中的单词时,使用这些单词就可以确定任何文档的正面或负面的极性.\n",
    "    \n",
    "- MPQA 主观词典\n",
    "    \n",
    "    MPQA代表的是多视角的问题回答,包含了有匹兹堡大学维护的大量资源,观点语料库,主观字典,词性标注,基于参数的词汇以及辩论数据集.\n",
    "    \n",
    "    它们中很多资源可以用于分析人类情感和情绪.相关论文:\"Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis\"\n",
    "    \n",
    "    下载主观词典网址:http://mpqa.cs.pitt.edu/lexicons/subj_lexicon/\n",
    "    \n",
    "    主观性的提示词语可以在档案解压后的subjclueslen1-HLTEMNLP05.tff中找到.\n",
    "- SentiWordNet\n",
    "    \n",
    "    一个用于情感分析和意见挖掘的词典资源.赋予了三个情感分值,包括正面极性分值,负面极性分值和客观分值.\n",
    "    \n",
    "    更多信息请了解:http://sentiwordnet.isti.cnr.it\n",
    "- VADER词典\n",
    "\n",
    "    该词典是一个基于规则的情感分析框架,专为社交媒体分析情感而建立.\n",
    "    \n",
    "    更多信息请参阅:https://github.com/cjhutto/vaderSentiment\n",
    "- Pattern词典\n",
    "\n",
    "    pattern是一个完整的自然语言处理,文本分析和信息检索的函数包.\n",
    "    \n",
    "    该函数包有一个情感分析模块,以及情绪分析和文本模式分析模块\n",
    "    \n",
    "    对于情感分析,该模块通过将文本分为句子,词干化,对词干进行词性标注等步骤分析任何文本.\n",
    "    \n",
    "    它的主观情感词典为:github.com/clips/pattern/blob/master/pattern/text/en/en-sentiment.xml\n",
    "    \n",
    "    该词典包含极性,主观,强度,自信的评分,以及词性标签,WordNet标识等.\n",
    "    \n",
    "    pattern推荐的阈值为0.1,高于该值时情感为正面,低于该值时为负面."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFINN词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "afn = Afinn(emoticons=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "#get synset for 'good'\n",
    "good = swn.senti_synsets('good','n')[0]\n",
    "\n",
    "#print synset sentiment scores\n",
    "print('Positive Polarity Score:', good.pos_score())\n",
    "print('Negative Polarity Score:', good.neg_score())\n",
    "print('Objective Score:', good.obj_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from normalization import normalize_accented_characters, html_parser, strip_html\n",
    "\n",
    "def analyze_sentiment_sentiwordnet_lexicon(review, verbose=False):\n",
    "    #pre-process text\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html_parser.unescape(review)\n",
    "    review = strip_html(review)\n",
    "    \n",
    "    #tokenize and POS tag tet tokens\n",
    "    text_tokens = nltk.word_tokenize(review)\n",
    "    tagged_text = nltk.pos_tag(text_tokens)\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    \n",
    "    #get wordnet synsets based on POS tags\n",
    "    #get sentiment scores if synsets are found\n",
    "    for word ,tag in tagged_text:\n",
    "        ss_set = None\n",
    "        \n",
    "    if 'NN' in tag and swn.senti_synsets(word, 'n'):\n",
    "        ss_set = swn.senti_synsets(word, 'n')[0]\n",
    "    elif 'VB' in tag and swn.senti_synsets(word,'v'):\n",
    "        ss_set = swn.senti_synsets(word,'v')[0]\n",
    "    elif 'JJ' in tag and swn.senti_synsets(word,'a'):\n",
    "        ss_set = swn.senti_synsets(word, 'a')[0]\n",
    "    elif 'RB' in tag and swn.senti_synsets(word, 'r'):\n",
    "        ss_set = swn.senti_synsets(word, 'r')[0]\n",
    "    #if senti-synset is found\n",
    "    if ss_set:\n",
    "        #add scores for all found synsets\n",
    "        pos_score += ss_set.pos_score()\n",
    "        neg_score += ss_set.neg_score()\n",
    "        obj_score += ss_set.obj_score()\n",
    "        token_count += 1\n",
    "        \n",
    "    #aggregate final scores\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score)/token_count, 2)\n",
    "    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
    "\n",
    "    if verbose:\n",
    "        norm_obj_score = round(float(obj_score)/token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score)/token_count,2)\n",
    "        norm_neg_score = round(float(neg_score)/token_count,2)\n",
    "        # to display results in a nice table\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score,\n",
    "                                        norm_pos_score,norm_neg_score,norm_final_score]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                     ['Predicted_Sentiment',\n",
    "                                                                     'Objectivity',\n",
    "                                                                     'Positive',\n",
    "                                                                     'Negative',\n",
    "                                                                     'Overall']],\n",
    "                                                            labels=[[0,0,0,0,0],[0,1,2,3,4]])\n",
    "                                      )\n",
    "        print sentiment_frame\n",
    "        \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#detail sentiment analysis for sample reviews\n",
    "for review, review_sentiment in sample_data:\n",
    "    print 'Review:'\n",
    "    print review\n",
    "    print \n",
    "    print('Labeled Sentiment:', review_sentiment)\n",
    "    print\n",
    "    final_sentiment = analyze_sentiment_sentiwordnet_lexicon(review,verbose=True)\n",
    "    print '-'*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict sentiment for test movie reviews dataset\n",
    "sentiwordnet_predictions = [analyze_sentiment_sentiwordnet_lexicon(review) for review in test_reviews]\n",
    "\n",
    "#get model erformance statistics\n",
    "print('Performance metrics:')\n",
    "\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                            predicted_labels=sentiwordnet_predictions,\n",
    "                            positive_class='positive')\n",
    "print('\\nConfusion Matrix:')\n",
    "\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                        predicted_labels=sentiwordnet_predictions,\n",
    "                        classes=['positive','negative'])\n",
    "\n",
    "print('\\nClassification report:')\n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                             predicted_labels=sentiwordnet_predictions,\n",
    "                             classes=['positive','negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VADER词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def analyze_sentiment_vader_lexicon(review, threhold=0.1, verbose=False):\n",
    "    #pre-process text\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html_parse.unescape(review)\n",
    "    #analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    #get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold else 'negative'\n",
    "    \n",
    "    if verbose:\n",
    "        #display detailed sentiment statistic\n",
    "        positive = str(round(scores['pos'], 2)*100) + '%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive, negative, neutral]],\n",
    "                                      columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                    ['Predicted Sentiment','Polarity Score','Positive','Negative','Neutral']],\n",
    "                                                           labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "        \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get detailed sentiment statistics\n",
    "for review, review_sentiment in sample_data:\n",
    "    print 'Review:'\n",
    "    print review\n",
    "    print\n",
    "    print 'Labeled Sentiment:', review_sentiment\n",
    "    print\n",
    "    final_sentiment = analyze_sentiment_vader_lexicon(review,threshold=0.1,verbose=True)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict sentiment for test movie reviews dataset\n",
    "vader_predictions = [analyze_sentiment_vader_lexicon(review, threshold=0.1) for review in test_reviews]\n",
    "\n",
    "#get model performance statistics\n",
    "print 'Performance metrics:'\n",
    "display_evaluation_metrics(true_labels=test_sentiments, predicted_labels=vader_predictions, positive_class='positive')\n",
    "\n",
    "print('\\n Confusion Matrix:')\n",
    "\n",
    "display_confusion_matrix(true_labels=test_sentiments\n",
    "                        predicted_labels=vader_predictions,\n",
    "                        classes=['positive','negative'])\n",
    "print('\\nClassification report:')\n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                             predicted_labels=vader_predictions,\n",
    "                             classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern 词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.en import sentiment, mood, modality\n",
    "def analyze_sentiment_pattern_lexicon(review, threshold=0.1, verbose=False):\n",
    "    #pre-process text\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html_parser.unescape(review)\n",
    "    review = strip_html(review)\n",
    "    \n",
    "    #analyze sentiment for the text document\n",
    "    analysis = sentiment(review)\n",
    "    sentiment_score = round(analysis[0], 2)\n",
    "    sentiment_subjectivity = round(analysis[1],2)\n",
    "    \n",
    "    #get final sentiment\n",
    "    final_sentiment = 'positive' if sentiment_score >= threshold else 'negative'\n",
    "    \n",
    "    if verbose:\n",
    "        #display detailed sentiment statistics\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, sentiment_score, sentiment_subjectivity]],\n",
    "                                      columns=pd.Multiindex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                    ['Predicted Sentiment','Polarity Score','Subjectivity Score']],\n",
    "                                                           labels=[[0,0,0],[0,1,2]]))\n",
    "        \n",
    "        print sentiment_frame\n",
    "        assessment = analysis.assessments\n",
    "        assessment_frame = pd.DataFrame(assessment, columns=pd.MultiIndex(levels=[['DETAILED ASSESSMENT STATS:'],\n",
    "                                                                                 ['Key Terms','Polarity Score',\n",
    "                                                                                 'Subjectivity Score','Type']],\n",
    "                                                                         labels=[[0,0,0,0],[0,1,2,3]]))\n",
    "        print assessment_frame\n",
    "        print\n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get detailed sentiment statistics\n",
    "for review, review_sentiment in sample_data:\n",
    "    print 'Review:'\n",
    "    print review\n",
    "    print\n",
    "    print 'Labeled Sentiment:', review_sentiment\n",
    "    print\n",
    "    final_sentiment = analyze_sentiment_pattern_lexicon(review, threshold=0.1, verbose=True)\n",
    "    print '-'*40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for review, review_sentiment in sample_data:\n",
    "    print 'Review:'\n",
    "    print review\n",
    "    print 'Labeled Sentiment:', review_sentiment\n",
    "    print 'Mood:', mood(review)\n",
    "    mode_score = modality(review)\n",
    "    print('Modality Score:', round(mod_score, 2))\n",
    "    print('Certainty:', 'Strong' if mod_score>0.5 else 'Medium' if mod_score > 0.35 else 'Low')\n",
    "    print '-'*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict sentiment for test movie reviews dataset\n",
    "pattern_predictions = [analyze_sentiment_pattern_lexicon(review, threshold=0.1) for review in test_reviews]\n",
    "\n",
    "#get model performance statistics\n",
    "print('Performance metrics:')\n",
    "display_evaluation_metrics(true_labels=test_sentiments,predicted_labels=pattern_predictions,positive_class='positive')\n",
    "\n",
    "print('\\nConfusion Matrix:')\n",
    "display_confusion_matrix(true_labels=test_sentiments, predicted_labels=pattern_predictions, classes=['positive','negative'])\n",
    "\n",
    "print('\\cClassification report:')\n",
    "display_classification_report(true_labels=test_sentiments, predicted_labels=pattern_predictions, classes=['positive','negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
